---
title: "Contrastive Counterfactual Visual Explanations With Overdetermination"
collection: publications
date: 2021-09-20
venue: arXiv
authors: "Adam White, Kwun Ho Ngan, James Phelan, Saman Sadeghi Afgeh, Kevin Ryan, Constantino Carlos Reyes-Aldasoro, Artur d'Avila Garcez"
paperurl: https://arxiv.org/abs/2106.14556
type: Pre-print
theme: "imageprocessing, ML_AI_DL"
resources: " "
---
<h2> Abstract </h2>  <br>
A novel explainable AI method called CLEAR Image is introduced in this paper. CLEAR Image is based on the view that a satisfactory explanation should be contrastive, counterfactual and measurable. CLEAR Image explains an image's classification probability by contrasting the image with a corresponding image generated automatically via adversarial learning. This enables both salient segmentation and perturbations that faithfully determine each segment's importance. CLEAR Image was successfully applied to a medical imaging case study where it outperformed methods such as Grad-CAM and LIME by an average of 27% using a novel pointing game metric. CLEAR Image excels in identifying cases of "causal overdetermination" where there are multiple patches in an image, any one of which is sufficient by itself to cause the classification probability to be close to one.

{% include paper-research-resources.html %}
